{"meta":{"title":"Hogwarts","subtitle":"Gryffindor","description":"Magic","author":"Sirius Black","url":"http://yoursite.com"},"pages":[{"title":"tags","date":"2018-06-06T12:41:24.000Z","updated":"2018-06-06T12:41:24.410Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"小天狼星","date":"2017-06-06T12:54:44.000Z","updated":"2018-09-14T07:30:08.081Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"http://blog.wyccc.top"}],"posts":[{"title":"ssh端口转发","slug":"ssh_port_forwarding","date":"2018-09-14T11:43:23.000Z","updated":"2018-09-15T02:56:50.777Z","comments":true,"path":"2018/09/14/ssh_port_forwarding/","link":"","permalink":"http://yoursite.com/2018/09/14/ssh_port_forwarding/","excerpt":"","text":"​ ssh是secure shell的缩写，是专为远程登录会话和其他网络服务提供安全性的协议。传统的网络服务协议，如ftp、telnet等都是通过明文传输数据，是不安全的。ssh可以把你的传输数据进行加密，并且数据是经过压缩的可以节省流量。 验证方式ssh有两种验证方式，分别是口令验证和密钥验证。 口令验证就是通过账号和口令登录远程机器。 密钥验证是生成一个密钥对，将公钥放到远程服务器上，把私钥放在自己本地机器上。登录的时候远程主机会发来一串随机字符串，本地用私钥加密发回去，如果远程主机用公钥解密成功则认为这个用户合法，直接就可以登录成功。 最简单的用法ssh @ user是想要登录远程主机的用户名，host是远程主机的地址，ssh默认使用的端口是22，如果想要指定端口可以用-p 来指定，建议远程服务器修改一下ssh端口防止被攻击。下面是一个示例 1ssh root@88.88.88.88 连接远程机器88.88.88.88，并用root用户登录。 远程执行命令ssh可以登录到指定主机，然后执行命令。也可以在ssh命令后跟想要执行的命令，这样命令执行结束后就会直接退出登录。 1ssh root@88.88.88.88 'jps' 查看88.88.88.88这台机器用root用户运行的java程序。 本地端口转发可以通过ssh绑定本地端口，将本地某个端口转发到远程主机的指定端口，如远程主机有一个http服务监听了8080端口，但是8080端口并不对公网开放，那么就可以用ssh转发来达到本地访问效果。 1ssh -L 2121:127.0.0.1:8080 root@88.88.88.88 -p 4477 这样就ssh就会监听本地2121端口，所以对本地2121端口的访问都会被转发到远程机器的8080端口上，当然也可以将127.0.0.1改成别的远程机器能访问到的ip。这里的-p是指定远程机器的ssh服务端口，我这边设置的是4477。 远程端口转发本地执行ssh命令，可以指定让远程机器监听一个端口，所有对这个端口的访问都转发到本地，从而实现内网穿透。 1ssh -R 7777:10.0.0.5:7000 root@88.88.88.88 -p 4477 本地通过ssh连向远程机器，并让远程机器监听7777端口，所有对这个端口的访问都转发到本地机器。即对远程机器7777端口的访问和在本地访问10.0.0.5:7000地址效果是一样的。 这边我转发的是一个web服务，转发成功后在浏览器打开88.88.88.88:7777并不能正常打开，登录远程机器查看监听状态发现监听的是127.0.0.1的7777端口。这和sshd的安全机制有关，默认sshd只会转发127.0.0.1这个地址的端口，我们要实现转发所有ip可以在远程机器进行以下配置。 123vi /etc/ssh/sshd_config# 将GatewayPorts配置成yesservice sshd restart 再重新按照之前的步骤转发下远程端口，访问成功。 转入后台运行前面的端口转发命令，当执行成功后就会进入远程的shell操作页面，当exit的时候，ssh连接也会断开。我们可以通过-N参数不让他进入远程sheel操作页面。 1ssh -NR 7777:10.0.0.5:7000 root@88.88.88.88 -p4477 这样还不够，我们希望能在后台运行，而不用一只维持一个打开的窗口。可以用-f参数指定。 1ssh -fNR 7777:10.0.0.5:7000 root@88.88.88.88 -p4477 这样就可以操作本地shell或者关闭当前shell，后台运行的端口转发通道还是开着的。想要关闭可以用kill命令把进程杀死。","categories":[{"name":"Shell","slug":"Shell","permalink":"http://yoursite.com/categories/Shell/"},{"name":"Linux","slug":"Shell/Linux","permalink":"http://yoursite.com/categories/Shell/Linux/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://yoursite.com/tags/Shell/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"}]},{"title":"jshell - Java官方的REPL工具","slug":"jshell","date":"2018-09-13T12:15:13.000Z","updated":"2018-09-14T07:21:03.765Z","comments":true,"path":"2018/09/13/jshell/","link":"","permalink":"http://yoursite.com/2018/09/13/jshell/","excerpt":"","text":"​ Jshell是java9新出的基于Java语言的REPL(Read-Eval-Print Loop)命令行工具。它允许不适用类以及main方法就可以执行Java代码，类似于Python、JavaScript等脚本语言。可以说是一个非常好的工具，以后碰到需要测试否个不熟悉的方法或测试某个逻辑，再也不需要新建一个类写一个main方法或测试方法去运行，只要打开jshell输入命令执行就好了。 一个简单的例子123456789➜ ~ jshell| Welcome to JShell -- Version 10.0.1| For an introduction type: /help introjshell&gt; System.out.println(\"Hello World!!!\")Hello World!!!jshell&gt; /exit| Goodbye 在命令行直接输入jshell打开jshell交互界面，输入System.out.println(“Hello World!!!”)即可看到输出结果，最后输入/exit退出。 变量声明当一个表达式最终是返回一个值时，且没有显示指定该值的变量，那么jshell会自动将该对象的引用设置到一个系统生成的变量上，看下面的例子。 1234jshell&gt; 1+1$3 ==&gt; 2jshell&gt; \"Hello World!!!\".substring(5)$4 ==&gt; \" World!!!\" 1+1的结果是2，但是我们并没有将结果赋值给一个变量，所以jshell自动将结果值赋值给了他自己声明的变量$3上。继续看下面执行的语句，”Hello World!!!”.substring(5)，其实就是调用了String类的substring()方法。这里就衍生出一个问题，在测试的时候可能连自己都搞不清楚返回的值到底是什么类型的,可能一个不小心以为返回的值是String调用了substring方法，最后报错发现是int类型的。这里推荐进入jshell命令行时加一个参数-v打开详情模式，会在变量赋值后打印变量类型。 1234567➜ ~ jshell -v| Welcome to JShell -- Version 10.0.1| For an introduction type: /help introjshell&gt; \"Hello World!!!\".substring(5)$1 ==&gt; \" World!!!\"| created scratch variable $1 : String 声明方法声明方法也很简单，直接按照java中方法的格式一行一行输进去就可以。 12345678jshell&gt; String hello(String name) &#123; ...&gt; return \"Hello \" + name; ...&gt; &#125;| created method hello(String)jshell&gt; hello($1)$6 ==&gt; \"Hello 5\"| created scratch variable $6 : String 想要修改方法声明，用同样的方法前面再输一次即可。 辅助命令123456789101112131415161718192021222324252627jshell&gt; /vars| String $1 = \"5\"| String $6 = \"Hello 5\"| String $8 = \"Hi 5\"| int $10 = 0jshell&gt; /methods| String hello(String)| int hehe()| which cannot be invoked until method what() is declaredjshell&gt; /list 1 : \"Hello World!!!\".substring(5) 2 : $1 = \"5\" 3 : $1 4 : System.out.println($1) 6 : hello($1) 7 : String hello(String name) &#123; return \"Hi \" + name; &#125; 8 : hello($1) 9 : int hehe() &#123; what(); return 1; &#125; 10 : hehe() /vars列出当前所有变量，/methods列出当前声明的方法，/list类似于Linux的history列出命令历史可以输入/来打印所有的辅助命令(没错，jshell支持tab键补全) 123jshell&gt; //! /? /drop /edit /env /exit /help /history /imports /list /methods /open /reload /reset /save /set /types /vars 执行jshell脚本可以通过编写脚本来执行jshell命令，像linux的shell脚本一样，然后通过jshell -s &lt;jshell_file&gt;来执行 1jshell --startup test_jshell.jsh 推荐在脚本最后一行加入/exit，不然脚本执行完后会停留在jshell交互页面。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"Java并发包 - CopyOnWriteArrayList","slug":"copy_on_write_array_list","date":"2018-08-29T11:05:00.000Z","updated":"2018-08-29T09:51:21.820Z","comments":true,"path":"2018/08/29/copy_on_write_array_list/","link":"","permalink":"http://yoursite.com/2018/08/29/copy_on_write_array_list/","excerpt":"","text":"CopyOnWriteArrayList是JDK并发包里面的一个类，用于提供可以多线程并发访问的一个List结构。比较适合在读取多改动少的情景下使用，看名字就可知基本原理，是在写入的时候不直接操作原数组，而是重新拷贝一个新的数组在新的数组里进行写入操作。 源码分析先来看看这个类的继承结构，没有继承任何类，但是实现了4个接口，包括1个普通接口List和3个标记接口。 12public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable List不用说，这是一个List基础操作接口。RandomAccess表式这个接口支持随机访问，即随机访问的时间复杂度是O(1)；Cloneable表示这个类可以被clone()；Serializable表示这个类可以被序列化和反序列化。 下面我们就用List操作中最常用的几个方法(get、add、remove、set)来分析CopyOnWriteArrayList是如何实现线程安全的。 读取元素（get）1234567private E get(Object[] a, int index) &#123; return (E) a[index];&#125;public E get(int index) &#123; return get(getArray(), index);&#125; 连锁都没有，竟然比ArrayList还要简介！没什么可说的。 添加元素（add）1234567891011121314public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 可以看到，add操作是加了锁的，也就是说同一时间只有一个线程可以进行add操作。看add操作的可以发现并没有修改原有的array对象，而是将原有的array对象重新拷贝了一份，对新拷贝的对象执行新增操作。所以在此期间对该数组的读取操作都还是在原有数组上。锁的目的有只有一个，保证同一时刻就一个线程对array引用赋值。而array变量的可见效则由volatile关键字保证，因为读线程并不会加锁。 根据下标删除元素（remove index）12345678910111213141516171819202122public E remove(int index) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); int numMoved = len - index - 1; if (numMoved == 0) setArray(Arrays.copyOf(elements, len - 1)); else &#123; Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125;&#125; remove操作和add操作大同小异，因为加了锁，所以加锁段的代码可以肆无忌惮的写。逻辑也很简单，就是新建一个原数组长度-1的数组，将除了被删除元素的其他元素拷贝到新的数组，并将新的数组设置到array变量上。 根据对象删除元素（remove object）1234567891011121314151617181920212223242526272829303132333435363738public boolean remove(Object o) &#123; Object[] snapshot = getArray(); int index = indexOf(o, snapshot, 0, snapshot.length); return (index &lt; 0) ? false : remove(o, snapshot, index);&#125;private boolean remove(Object o, Object[] snapshot, int index) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] current = getArray(); int len = current.length; if (snapshot != current) findIndex: &#123; int prefix = Math.min(index, len); for (int i = 0; i &lt; prefix; i++) &#123; if (current[i] != snapshot[i] &amp;&amp; eq(o, current[i])) &#123; index = i; break findIndex; &#125; &#125; if (index &gt;= len) return false; if (current[index] == o) break findIndex; index = indexOf(o, current, index, len); if (index &lt; 0) return false; &#125; Object[] newElements = new Object[len - 1]; System.arraycopy(current, 0, newElements, 0, index); System.arraycopy(current, index + 1, newElements, index, len - index - 1); setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 这个方法稍微有点复杂，也是为了性能考虑。最终移除过程是由remove(Object o, Object[] snapshot, int index)方法操作的，在这之前先检查一下数组里面有没有对应的移除元素，这个过程是不需要加锁的，所以如果数组里没有被移除元素，这个移除方法调用并不会影响其他修改操作。 再来看看最终操作移除的方法remove(Object o, Object[] snapshot, int index)。因为在这期间数组可能已经发生了变化，如果是我来写，应该会暴力的再调用indexOf方法查找新数组里待删除元素index。而JDK做法则不然，也是对性能考虑到了极致。因为equals是用户自定义的方法，时间复杂度并不能确定，所以JDK代码中将equals方法的调用次数降到了最低。新数组分成两段判断，第一段是[0, Math.min(index, len)]，index是老数组里待删元素的index，len是新数组的长度。这段数组内的元素先判断新老数组是否相同(相同则表示这个元素没变过，因为老数组在index位置才找到元素，所以在这之前的元素都是不符合条件的。)，不相同才调用equals方法。第二段还是调用indexOf，用equals依次判断。 指定index设置元素（set）12345678910111213141516171819202122set(int index, E e)public E set(int index, E element) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); E oldValue = get(elements, index); if (oldValue != element) &#123; int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len); newElements[index] = element; setArray(newElements); &#125; else &#123; // Not quite a no-op; ensures volatile write semantics setArray(elements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125;&#125; 如果要设置的值和指定位置的值不一致则设置并替换数组，但是如果是一样的就比较有意思了，会将原数组重新设置到array变量上，看似是一个无用的操作，实则不然，可以看到作者还写了条注释解释了下。这其实牵涉到jdk约定的给所有java并发包(java.util.concurrent)里面的集合添加元素需要遵从的语义。贴一下官方文档解释 Actions in a thread prior to placing an object into any concurrent collection happen-before actions subsequent to the access or removal of that element from the collection in another thread. 翻译一下，将对象放入集合的操作和从集合中读取或删除对象操作之间存在happen-before关系。这是jdk给并发包以及下面的子包所定义的语义，我们这里的set方法是怎么保证语义的呢？就是通过对volatile变量array的操作，如果把上面这句看似无用的代码删掉，那么就不能保证这种关系。这是我网上搜的更详细的解释 https://stackoverflow.com/questions/28772539/why-setarray-method-call-required-in-copyonwritearraylist 应用场景从源码可以看出，CopyOnWriteArrayList适合读多写少的场景，读的时候不加锁，效率和普通的ArrayList一样，但是写的时候开销很大，需要开一个新的数组将原有的对象原封不动的拷贝进去。所以CopyOnWriteArrayList没有扩容的概念，每次修改是生成一个新的数组。此外，CopyOnWriteArrayList容器保证的是最终一致性，也就是说在写入方法返回前，你是不知道读取的值是写入前的还是写入后的。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"concurrent","slug":"concurrent","permalink":"http://yoursite.com/tags/concurrent/"}]},{"title":"用Docker部署shadowsocks","slug":"deploy_shadowsocks_with_docker","date":"2018-08-27T11:05:00.000Z","updated":"2018-08-29T09:55:55.869Z","comments":true,"path":"2018/08/27/deploy_shadowsocks_with_docker/","link":"","permalink":"http://yoursite.com/2018/08/27/deploy_shadowsocks_with_docker/","excerpt":"","text":"最近了解了下Docker容器的基础知识，就想着将自己服务器上的服务都容器化，方便管理，还能让机器保持整洁不需要安装稀奇古怪的依赖，直接pull一个对应服务的镜像就好了。 就先从shadowsocks开始吧，这篇主要就讲如何在linux机器上通过Docker部署一个Shadowsocks服务。 下载容器docker pull mritd/shadowsocks 首先保证已经安装好Docker环境，通过一条命令就可以拉取远程的镜像。mritd/shadowsocks这个镜像是dockerhub上pull次数最多的shadowsocks服务镜像，我就以这个镜像来部署。这个镜像即成了shadowsocks-libev、kcptun、simple-obfs，我这里只用到shadowsocks-libev。 启动容器启动一个最简单的ss服务测试一下 1docker run -dt --name ss -p 6443:6443 mritd/shadowsocks -s \"-s 0.0.0.0 -p 6443 -m aes-256-cfb -k test123 --fast-open\" 依次分析各个参数作用。 -d 后台启动，如果不指定，退出后容器就会停止 —name 指定容器名字，后面进入容器、停止开始容器、删除容器等操作都可以通过指定容器名字来执行 -p 端口映射宿主主机的6443端口映射到容器6443端口 -s 指定ss-server命令后面的执行参数 执行上面的命令，用docker ps查看正在运行的容器状态，发现已经启动。本地用shadowsocks客户端连接可以连接成功，说明已经可以正常使用了。 通过config.json配置服务上面这种方式只支持单端口的ss服务，我之前的ss服务是通过json配置文件配置了多个服务端口。在github上提issue给镜像作者，给的答复是这个 1docker run -dt --name ssserver -p 6443:6443 -p 6500:6500/udp -v `pwd`/config.json:/config.json mritd/shadowsocks -m \"ss-server\" -s \"-c /config.json\" -x -e \"kcpserver\" -k \"-t 127.0.0.1:6443 -l :6500 -mode fast2\" 然而根据给定的配置，不能正常启动ss容器。没办法，提issue一来一回太麻烦了，自己研究吧。 上面通过指定-c config.json方式启动，容器直接结束了，也看不到输出信息。（我对docker不太熟，可能有方法看到输出信息） 只能先让容器起来，进容器看具体是什么问题。用能正常启动容器的命令挂在上config.json文件来启动，进入容器（docker exec -it ss bash）。 用ps -ef | grep ss查看当前ss服务的启动命令，发现输出如下 123bash-4.4# ps -ef | grep ss 5 root 0:00 ss-server -s 0.0.0.0 -p 6443 -m aes-256-cfb -k test123 --fast-open 10 root 0:00 grep ss 可以看到ss-server后面的参数就是docker执行时-s指定的参数。在容器中试一下直接用ss-server命令加上-c config.json参数来执行，打印出使用信息，应该是配置文件配置不正确导致的。 我的配置文件之前shadowsocks一直在使用的，但是我安装的是正常的shadowsocks服务，启动命令是ssserver，而这个镜像里面安装的是shadowsocks-libev服务，启动命令是ss-server。一查发现ss-server命令不支持.json配置文件启动，需要用ss-manager代替之。 在容器中执行命令ss-manager -c config.json，控制台输出如下： 123452018-08-27 17:33:25 INFO: using the default manager address: 127.0.0.1:88392018-08-27 17:33:25 INFO: using tcp fast open2018-08-27 17:33:25 INFO: running from root user2018-08-27 17:33:25 INFO: try to bind interface: 0.0.0.0, port: 64432018-08-27 17:33:25 INFO: try to bind interface: 0.0.0.0, port: 6444 已经绑定了我需要的端口，也没有报错，说明已经启动了。接下来就把这条命令移到容器启动的时候运行。 退出容器，docker stop ss、docker rm ss停止并删除之前的容器，执行如下命令 1docker run -d --name ss -p 6400-6500:6400-6500 -v `pwd`/config.json:/config.json -e SS_CONFIG=\"-c /config.json\" mritd/shadowsocks -m \"ss-manager\" -v用来挂在宿主主机的文件或目录到容器内，pwd是当前路径，这里将当前目录的config.json文件挂在到容器的/config.json路径下。 -e SS_CONFIG用来指定命令参数，和前面的-s指定参数效果一样。 -m 用来指定启动参数，之前默认是ss-server不符合我们的要求，改成ss-manager -p 用来指定端口，因为我们想要映射多个端口，所有用来指定一串端口绑定 启动成功后用shadowsocks客户端连接，指定的两个端口都可以使用了。 进入最新的容器，用ps -ef | grep ss命令查看ss进程，输出如下信息 12345 1 root 0:00 &#123;entrypoint.sh&#125; /bin/bash /entrypoint.sh -m ss-manager 5 root 0:00 ss-manager -c /config.json 7 root 0:00 ss-server --manager-address 127.0.0.1:8839 -f /root/.shadowsocks/.shadowsocks_6443.pid -c /root/.shadowsocks/.shadowsocks_6443.conf -t 300 --fast-open -s 0.0.0.0 9 root 0:00 ss-server --manager-address 127.0.0.1:8839 -f /root/.shadowsocks/.shadowsocks_6444.pid -c /root/.shadowsocks/.shadowsocks_6444.conf -t 300 --fast-open -s 0.0.0.033 root 0:00 grep ss 说明ss-manager只是一个启动器，读取出配置，每个端口都起一个ss-server进程来监控。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"},{"name":"Shadowsocks","slug":"Shadowsocks","permalink":"http://yoursite.com/tags/Shadowsocks/"}]},{"title":"JDK SPI实现原理","slug":"jdk_spi","date":"2018-05-27T11:05:00.000Z","updated":"2018-08-29T09:57:15.471Z","comments":true,"path":"2018/05/27/jdk_spi/","link":"","permalink":"http://yoursite.com/2018/05/27/jdk_spi/","excerpt":"","text":"SPI全称Service Provider Interface，是JDK官方提供的一种服务发现(look up)机制。 一般分为接口提供方和接口实现方，权威方提供接口标准（如JDBC标准，是由JDK提供的用于数据库连接的标准接口），接口实现方提供具体实现（如针对JDBC的mysql实现是由mysql官方提供的）。 下面我们通过mysql的实现来了解一下SPI具体是怎么工作的。 mysql-connector-java的jar包中，有META-INF/services/java.sql.Driver文件，内容如下 12com.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver SPI约定提供方需要在META-INF/services/目录下创建以接口名(包括接口路径的全限定名)命名的文件，文件内容是这个接口的具体实现。 由此说明mysql-connector-java提供了java.sql.Driver的实现，并且提供了两个实现。 那JDK具体是通过什么方式来读取这个文件并加载具体实现类的呢？不着急找答案，我们先看看mysql包是怎么使用的。用mysql客户端获取一个连接的标准代码如下： 1Connection connection = DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:3306/wukong\", username, password); DriverManager是JDK提供的一个支持类，因为不同版本实现有略微区别，逻辑还是相似的，我们以jdk10.0.1的代码为例分析。 getConnection()方法内部调用了ensureDriversInitialized()方法，这个方法职责就是用ServiceLoader加载所有的java.sql.Driver接口实现，最核心的代码就是下面几句 1234567891011121314AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); try &#123; while (driversIterator.hasNext()) &#123; driversIterator.next(); &#125; &#125; catch (Throwable t) &#123; // Do nothing &#125; return null; &#125;&#125;); 通过ServiceLoader来指定具体的SPI接口并得到一个Iterator对象，在迭代这个迭代器的时候会去找指定路径的文件(这里就是META-INF/services/java.sql.Driver)，并给指定的实现创建对象。DriverManager约定将所有的驱动存在registeredDrivers对象里，mysql的做法是在com.mysql.jdbc.Driver里面加一个静态块初始化一个自身对象并把对象注册到DriverManager.registeredDrivers中。所以mysql这种实现方式com.mysql.jdbc.Driver类其实被实例化了两次，第一次在类初始化的时候执行的静态块中，这个对象是最终使用的对象；第二次实例化是ServiceLoader迭代器调用next()时会通过反射实例化一次对象，这个对象直接被DriverManager扔掉了。静态块向DriverManager注册的代码如下： 1234567static &#123; try &#123; java.sql.DriverManager.registerDriver(new Driver()); &#125; catch (SQLException E) &#123; throw new RuntimeException(\"Can't register driver!\"); &#125;&#125; 我们平时用mysql一般都只用com.mysql.jdbc.Driver类的实例化对象来操作，而META-INF/services/java.sql.Driver文件中声明了两个类实现，根据ServiceLoader类的加载规则，就算我们不使用com.mysql.fabric.jdbc.FabricMysqlDriver类实现，ServiceLoader也会帮我们实例化这个对象。而且在DriverManager根据指定url获取数据库连接时，DriverManager时遍历所有已注册的驱动依次尝试获取连接，直到拿到可用连接才会返回，代码如下： 123456789101112131415161718192021for(DriverInfo aDriver : registeredDrivers) &#123; // If the caller does not have permission to load the driver then // skip it. if(isDriverAllowed(aDriver.driver, callerCL)) &#123; try &#123; println(\" trying \" + aDriver.driver.getClass().getName()); Connection con = aDriver.driver.connect(url, info); if (con != null) &#123; // Success! println(\"getConnection returning \" + aDriver.driver.getClass().getName()); return (con); &#125; &#125; catch (SQLException ex) &#123; if (reason == null) &#123; reason = ex; &#125; &#125; &#125; else &#123; println(\" skipping: \" + aDriver.getClass().getName()); &#125;&#125; 这其实是一种资源浪费，内存中无缘无故多了一个com.mysql.fabric.jdbc.FabricMYSQLDriver类对象，而且不能被回收，获取Connection时也要根据具体的url依次判断每个Driver是否能根据此url来获取连接，效率并不是很高。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"spring scheme扩展","slug":"spring_custom_schema","date":"2018-05-27T11:05:00.000Z","updated":"2018-08-29T09:58:24.298Z","comments":true,"path":"2018/05/27/spring_custom_schema/","link":"","permalink":"http://yoursite.com/2018/05/27/spring_custom_schema/","excerpt":"","text":"最近在看dubbo的代码，dubbo有属于自己的配置标签，可以在spring配置文件中使用。 123&lt;dubbo:application name=\"\" /&gt;&lt;dubbo:registry protocol=\"zookeeper\" address=\"\"/&gt;&lt;dubbo:reference id=\"test\" interface=\"\" check=\"false\"/&gt; 诸如以上这些标签，都是dubbo程序自己根据需要创建的自定义表情。 Spring支持自建scheme来描述一些自定义的xml bean，对于普通开发者来说意义不大，但是对于一些第三方组件来说很有用，可以开发自己的标签来提供给用户配置。 实现原理Spring通过解析xml的内容，通过namespace找到标签对应的xsd文件和解析器的类。先根据xsd的规则检验配置文件是否符合规则，再根据配置的NamespaceHandler将标签配置内容转换成Bean交给Spring管理。 简单例子下面通过一个简单的例子来看一下Spring自定义标签的过程。 定义一个需要配置的Bean12345public class User &#123; private String name; private int age; ...&#125; 根据需要配置的Bean，定义一个xsd(XML Schema Definition)来描述这个需要配置的对象123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;xsd:schema xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns=\"http://www.mycompany.com/schema/my\" targetNamespace=\"http://www.mycompany.com/schema/my\" elementFormDefault=\"qualified\" attributeFormDefault=\"unqualified\"&gt; &lt;xsd:element name=\"user\"&gt; &lt;xsd:complexType&gt; &lt;xsd:attribute name=\"id\" type=\"xsd:ID\" /&gt; &lt;xsd:attribute name=\"name\" type=\"xsd:string\" use=\"required\" /&gt; &lt;xsd:attribute name=\"age\" type=\"xsd:int\" /&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt; &lt;xsd:element name=\"env\"&gt; &lt;xsd:complexType&gt; &lt;xsd:attribute name=\"id\" type=\"xsd:ID\" /&gt; &lt;xsd:attribute name=\"name\" type=\"xsd:string\" use=\"required\" /&gt; &lt;xsd:attribute name=\"test\" type=\"xsd:boolean\" /&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt;&lt;/xsd:schema&gt; 在spring配置文件中指定该xsd的namespace，并使用标签12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:my=\"http://www.mycompany.com/schema/my\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.mycompany.com/schema/my http://www.mycompany.com/schema/my.xsd\"&gt; &lt;!-- 自定义标签的形式 --&gt; &lt;my:user name=\"wyc\" age=\"17\" /&gt; &lt;my:env name=\"daily\" test=\"true\" /&gt; &lt;!-- 实例工厂的形式 --&gt; &lt;bean id=\"dateFormat\" class=\"java.text.SimpleDateFormat\"&gt; &lt;constructor-arg value=\"yyyy-MM-dd\"/&gt; &lt;/bean&gt;&lt;/beans&gt; 写标签的解析器我们定义了两个标签，需要写具体的解析器将xml元素解析成具体的bean，Spring提供了AbstractSingleBeanDefinitionParser抽象类来简化解析过程，我们只需关心转化过程就可以了。UserParser代码如下 123456789101112131415public class UserParser extends AbstractSingleBeanDefinitionParser &#123; @Override protected void doParse(Element element, BeanDefinitionBuilder builder) &#123; String name = element.getAttribute(\"name\"); int age = Integer.parseInt(element.getAttribute(\"age\")); element.setAttribute(\"id\", \"userId\"); builder.addPropertyValue(\"name\", name); builder.addPropertyValue(\"age\", age); &#125; @Override protected Class&lt;?&gt; getBeanClass(Element element) &#123; return User.class; &#125;&#125; 解析器需要一个NamespaceHandler来驱动，Spring同样提供了一个NamespaceHandlerSupport抽象类来简化驱动过程，我们只需要配置好标签对应的解析器就可以。 1234567public class UserNamespaceHandler extends NamespaceHandlerSupport &#123; @Override public void init() &#123; registerBeanDefinitionParser(\"user\", new UserParser()); registerBeanDefinitionParser(\"env\", new EnvParser()); &#125;&#125; 将具体的namespace配置和解析器连接起来在第3步中，namespace中配置了http://www.mycompany.com/schema/my 和 http://www.mycompany.com/schema/my.xsd两个地址，实际上这两个地址是我们虚构的，并不是一个真实地址。我们需要在META-INF中指定他们的本地路径。在META-INF文件夹下新建两个文件spring.handlers和spring.schemas，内容分别如下 spring.handlers 1http\\://www.mycompany.com/schema/my=com.wyc.test.spring.scheme.UserNamespaceHandler spring.schemas 1http\\://www.mycompany.com/schema/my.xsd=spring/scheme/wyc-demo.xsd spring.schemas是指定了对应的xsd地址，spring.handlers则指定了解析器的类地址。 这样启动spring容器后，spring就会根据配置初始化一个User对象和Env对象。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/tags/Spring/"}]},{"title":"spring exporter实现简单的RPC服务","slug":"spring_exporter","date":"2018-03-27T07:02:00.000Z","updated":"2018-08-28T09:30:29.709Z","comments":true,"path":"2018/03/27/spring_exporter/","link":"","permalink":"http://yoursite.com/2018/03/27/spring_exporter/","excerpt":"","text":"Spring Exporter是属于Spring web模块的一个功能，能通过Spring简单的实现基于http协议的RPC服务。 下面就来配置一个简单的demo，假设项目已经搭建好Spring mvc环境。 定义接口和具体实现 123456789public interface IUserService &#123; public String sayHello(String name);&#125;public class UserService implements IUserService &#123; @Override public String sayHello(String name) &#123; return String.format(\"hello, %s\", name); &#125;&#125; 接口和实现的定义最好分别写在不同的module，因为远程客户端需要引用接口的定义，我们只需要给接口定义就可以，要隐藏接口具体实现。 创建提供服务的Exporter 在配置文件中创建实现类的Bean，并初始化一个HttpInvokerServiceExporter对象，然后将得到的Exporter对象映射到想要的url上。 123456789101112131415&lt;bean id=\"userService\" class=\"com.wyc.test.service.impl.UserService\" /&gt;&lt;bean name=\"userExporter\" class=\"org.springframework.remoting.httpinvoker.HttpInvokerServiceExporter\"&gt; &lt;property name=\"service\" ref=\"userService\"&gt;&lt;/property&gt; &lt;property name=\"serviceInterface\" value=\"com.wyc.test.service.IUserService\"&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"urlMapping\" class=\"org.springframework.web.servlet.handler.SimpleUrlHandlerMapping\"&gt; &lt;property name=\"mappings\"&gt; &lt;props&gt; &lt;prop key=\"/userService\"&gt;userExporter&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt;&lt;/bean&gt; HttpInvokerServiceExporter对象可以和Controller对象一样，配置在HandlerMapping里面。 至此服务端就搭建完成了，下面来配置客户端。 Spring配置文件 1234&lt;bean id=\"remoteHelloService\" class=\"org.springframework.remoting.httpinvoker.HttpInvokerProxyFactoryBean\"&gt; &lt;property name=\"serviceUrl\" value=\"http://localhost:9999/userService\" /&gt; &lt;property name=\"serviceInterface\" value=\"com.wyc.test.service.IUserService\" /&gt;&lt;/bean&gt; 其中serviceUrl就是之前搭建的服务端对应服务的url，serviceInterface是该服务的接口 调用服务 和普通bean的操作一样，直接拿到对应的bean调用方法就可以。 1234String configPath = \"spring-application.xml\";ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(configPath);IUserService userService = context.getBean(\"remoteHelloService\", IUserService.class);System.out.println(userService.sayHello(\"wyc\")); 分别运行服务的和客户端程序，能正常输出。 其实spring远程RPC调用是基于org.springframework.remoting.httpinvoker.HttpInvokerServiceExporter，而这个对象是依赖于servlet标准实现的，所以并不需要基于spring-mvc，只要是基于servlet的web项目都可以用，下面就用最简单的servlet来实现远程调用，客户端和上面一样，我只介绍服务的代码。 创建一个Servlet 创建一个servlet对象HelloServlet，在init()方法中创建HttpInvokerServiceExporter对象，并配置需要代理的接口和实现。 123456789101112131415161718192021public class HelloServlet extends HttpServlet &#123; HttpInvokerServiceExporter exporter; @Override public void init() throws ServletException &#123; super.init(); exporter = new HttpInvokerServiceExporter(); exporter.setService(new UserService()); exporter.setServiceInterface(IUserService.class); try &#123; exporter.afterPropertiesSet(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; exporter.handleRequest(req, resp); &#125;&#125; HttpInvokerServiceExporter设置完后调用afterPropertiesSet()方法，doPost方法中直接调用handleRequest即可。 web.xml配置 然后在web.xml中配置对应的servlet地址，就和普通的servlet配置方式一样。 12345678&lt;servlet&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.wyc.test.servlet.HelloServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/HelloServlet&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 这样服务端就配置好了，其实和Spring mvc方式大同小异，只是这种方式是最纯粹的。Spring mvc是通过DispatcherServlet分发请求，通过HandlerMapping分发到对应的Export。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/tags/Spring/"}]},{"title":"Netty中的ByteBuf","slug":"netty_bytebuf","date":"2018-02-13T02:20:30.000Z","updated":"2018-08-28T07:15:02.025Z","comments":true,"path":"2018/02/13/netty_bytebuf/","link":"","permalink":"http://yoursite.com/2018/02/13/netty_bytebuf/","excerpt":"","text":"类结构简介 从图中可以看出，ByteBuf最重要的子类是AbstractByteBuf，其他四个除了EmptyByteBuf是实现了空ByteBuf外都是直接或者间接的引用AbstractByteBuf的。AbstractByteBuf有两个子类：AbstractDerivedByteBuf和AbstractReferenceCountedByteBuf，AbstractDerivedByteBuf的实现类也只是一层代理，并不会去实际操作数据；我们这里也主要讲下AbstractReferenceCountedByteBuf类及其实现类。 AbstractReferenceCountedByteBuf的实现类主要可以用两个维度去分类：Direct or Heap、Pooled or UnPooled（是否用了对象池）。 Direct or Heap，内存用的是堆内存还是直接内存HeapByteBuf，目前有两个buffer类是直接使用堆内存实现的，看名字就可以轻易找出来，就是UnpooledHeapByteBuf和PooledUnsafeDirectBytebuf。他们的特征是底层维护了一个字节数组(byte[])用来存储所需要的数据，所以内存是直接由JVM堆内存分配的。 DirectByteBuf，目前有三个buffer类是使用直接内存实现的，UnpooledUnsafeDirectByteBuf、UnpooledDirectByteBuf、PooledUnsafeDirectByteBuf以及PooledDirectByteBuf。这几个类是维护了一个DirectByteBuffer对象，由DirectByteBuffer对象申请对外内存来储存数据。 CompositeByteBuf，并不一定使用哪种内存方式，他只是将多个ByteBuf合并成一个进行操作，且无需拷贝。 Pooled or UnPooled，是否使用了对象池技术UnpooledByteBuf，没有使用对象池技术的ByteBuf PooledBytebuf，使用了对象池技术的ByteBuf ByteBuf接口介绍ByteBuf虽然定义的是一个抽象类，其实更像一个接口，没有实现任何方法。该类实现了ReferenceCounted接口，这个接口暂时还没去了解，看名字应该是引用计数相关，方便buffer使用完后释放。 为什么不直接用JDK提供的ByteBuffer进行数据传输呢？JKD自带的ByteBuffer有诸多局限性，比如不能自动扩展，读写共用一个指针等。BufferBuff内部维护了读写两个指针，可以更清晰的进行数据读写且不需要调用flip()方法进入读就绪。盗用一下netty文档上的示意图： 123456+-------------------+------------------+------------------+| discardable bytes | readable bytes | writable bytes || | (CONTENT) | |+-------------------+------------------+------------------+| | | |0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity ByteBuf用readerIndex和writerIndex两个指针将整个数据区域分成了三块，初始状态下readerIndex和writerIndex都是0。写入数据的时候，readable bytes这块会增加，相应的writable bytes这块会减小（不扩展的情况下）；读取数据的时候，readable bytes会减小，discardable bytes这块会增大；discardable 区理论上是已经没用的可丢弃的数据，可以通过discardReadBytes()方法把readable和writable区往前移。 如果一个操作让上面的不等式不成立此操作就会抛IndexOutOfBoundsException，write操作除外，write时会先检查writable bytes区大小，即使不够也会扩容，除非maxCapacity - writerIndex的值小于该操作写入的长度。操作之前可以通过ByteBuf接口提供的方法判断是否可写可读： 123456while(buf.isWritableBytes() &gt;= 4) &#123; buf.writeInt(1);&#125;while(buf.isReadable()) &#123; System.out.print(buf.readByte());&#125;","categories":[{"name":"netty","slug":"netty","permalink":"http://yoursite.com/categories/netty/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"netty","slug":"netty","permalink":"http://yoursite.com/tags/netty/"}]},{"title":"Java中的位运算","slug":"bitwise_operation_in_java","date":"2018-02-12T02:20:30.000Z","updated":"2018-08-28T07:13:54.292Z","comments":true,"path":"2018/02/12/bitwise_operation_in_java/","link":"","permalink":"http://yoursite.com/2018/02/12/bitwise_operation_in_java/","excerpt":"","text":"jdk源码中很多操作都涉及到位运算（如HashMap中取2^30用1 &lt;&lt; 30，ByteBuffer中将两个byte组成short用(short)((b1 &lt;&lt; 8) | (b0 &amp; 0xff))），因为计算机底层数据都是以二进制形式存储的，所有的运算最终其实都是转换成二进制进行位运算，所以直接位运算具有与生俱来的高效性。 位运算符号 &amp; 按位与运算 A &amp; B，每位进行比较，相同位都是1则此位结果为1，否则结果为0 | 按位或运算 A | B，每位进行比较，相同位都是0则此位结果为0，否则结果为1 ~ 按位非运算 ~A，单元运算，每位取反 ^ 异或运算 A ^ B，每位进行比较，相同位值相同则此位结果为0，否则结果为1。也称不进位加法 &lt;&lt; 左移运算 A &lt;&lt; n，把所有位向左移动n位，右边空出来的n位用0填充 >> 右移运算 A &gt;&gt; n，把所有位向右移动n位，左边空出来的n位用原数的符号位填充 >>> 无符号右移运算 A &gt;&gt;&gt; n，把所有位向右移动n位，左边空出来的n位用0填充 主要讲讲右移运算与无符号右移运算，右移运算是将所有位位移后左边用符号位补齐，所以运算完后符号位不变。而无符号右移运算运算完后都会用0补齐，所以运算完后肯定是正数。 举个例子，对于十进制的数DEC(-101) = BIN(11111111 11111111 11111111 10011011) 对其进行右移运算的结果是： BIN(11111111 11111111 11111111 10011011) &gt;&gt; 2 = BIN(11111111 11111111 11111111 11100110) 1int a = -101 &gt;&gt; 2; // 计算结果为-26 对其进行无符号右移运算的结果是： BIN(11111111 11111111 11111111 10011011) &gt;&gt; 2 = BIN(00111111 11111111 11111111 11100110) 1int a = -101 &gt;&gt;&gt; 2; // 计算结果为1073741798 基本数据类型间的转换 在这里我们只关心四种正数类型的转换，byte、short、int、long byte、short、int、long所能表示的范围是逐步扩大，前面能表示的范围是后面的一个子集。 所以将范围小的数据类型转换成范围大的数据类型，在Java中可以隐式转换且能保证值不变。如以下表达式： 12byte b = -11;int i = b; 因为要保证值不变，所以从byte转成long的时候多出的24位用原始byte值的符号位填充： BIN(11110101) -&gt; BIN(11111111 11111111 11111111 11110101) 将大范围的数据类型转成小范围的数据类型就有问题了，位数不够用！Java语言中对这种类型的转换也需要显示进行（强制类型转换），对于这种转换，做法很暴力，直接把多出来的高位抹去。 12int i = 10086;byte b = (byte) i; DEC(10086) = BIN(‭00000000 00000000 00100111 01100110‬) -&gt; BIN(01100110) 这种转换是很危险的，如果把一个范围不在-128~127的int类型的值强制转换为byte，将会得到一个和原值相差很大的数。（10086 -&gt; 102） 在JDK中的使用 来看看之前提到的ByteBuffer中根据两个byte组成一个有符号的short值 1(short)((b1 &lt;&lt; 8) | (b0 &amp; 0xff)); 首先需要了解，Java在对short和int类型的数进行位运算时会把他们转换成int类型的数在进行运算。 将两个byte转换成有符号的short值，理论上只需要把高位和低位拼在一起就好了，假设高位是0xXX，低位是0xYY，那么我们最终想要的值就是0xXXYY。最粗暴的方式： 1(short)( (0xXX &amp; 0xff) &lt;&lt; 8 + (0xYY &amp; 0xff) ) 把得到的值直接强制转换成short(抹去左边16位的0)后就是我们想要的值。 注意到(0xXX &amp; 0xff) &lt;&lt; 8这个表达式和0xXX &lt;&lt; 8这个表达式唯一区别就是得到的数前面16位是0还是f，如果0xXX第一位是0那么两个表达式计算结果一样；如果0xXX第一位是1，那么 ​ (0xXX &amp; 0xff) &lt;&lt; 8 –&gt; 0x0000XX00 0xXX &lt;&lt; 8 –&gt; 0xffffXX00 并不影响后16位的结果，而我们真正关心的只是后16位的值，前16位会在强转时被抹去，所以可以简化成： 1(short)( 0xXX &lt;&lt; 8 + (0xYY &amp; 0xff) ) 第一步0xXX &lt;&lt; 8得到的后25~32位永远是0，第二步0xYY &amp; 0xff得到的17~24永远是0，所以这两个数的加法可以直接用|运算代替，可以转化最终成表达式： 1(short)( 0xXX &lt;&lt; 8 | (0xYY) &amp; 0xff )","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"mysql创建用户","slug":"mysql_create_user","date":"2017-09-29T11:12:11.000Z","updated":"2018-09-10T11:15:52.040Z","comments":true,"path":"2017/09/29/mysql_create_user/","link":"","permalink":"http://yoursite.com/2017/09/29/mysql_create_user/","excerpt":"","text":"下面以添加用户test_user、将数据库test_database授权给test_user为例创建分配用户权限。 添加新用户允许指定ip段(192.168.1.0~192.168.1.255)用该用户访问数据库 1create user &apos;test_user&apos;@&apos;192.168.1.%&apos; identified by &apos;123456&apos; @前面是新建用户的账号，@后面是可以访问到的ip，identified by后面跟该用户的初始密码。 也可以指定ip或者直接用%来表示允许所有地址访问 1create user &apos;test_user&apos;@&apos;%&apos; identified by &apos;123456&apos; 分配指定数据库权限授予用户通过指定ip访问数据库的权限 1grant all privileges on `test_database`.* to &apos;test_user&apos;@&apos;%&apos; ; 也可以跳过创建用户步骤，直接用这个命令一起创建用户和分配表权限 1grant all privileges on `test_database`.* to &apos;test_user&apos;@&apos;%&apos; identified by &apos;123456&apos;; 撤销权限撤销指定用户的指定权限 1revoke all privileges ON `test_database`.* FROM &apos;test_user&apos;@&apos;%&apos;; 注意只能根据分配的权限去撤销，比如我给test_user用户分配了test_database.*的权限，撤销的时候不能只撤销这个库的某张表，只能全部撤销。 修改密码1set password for &apos;user_test&apos;@&apos;%&apos; = PASSWORD(&apos;newpassword&apos;); 删除用户1drop user &apos;user_test&apos;@&apos;%&apos;; 刷新权限配置注意，以上这些操作都需要通过刷新命令刷新进数据库缓存才能正式生效。 1flush privileges ; ⚠️注意事项我在配置用户及权限的时候碰到一个问题，新增的用户如果加密码登录总是提示Access denied，但是所有用户都可以免密登录。最后发现是因为mysql.user表中有一条‘‘@’localhost’记录引起的，一些版本的mysql安装默认会有该用户，手动删除即可。 1drop user &apos;&apos;@&apos;localhost&apos;","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"Java类加载和个块代码运行时机","slug":"java_class_init_","date":"2017-03-09T12:52:00.000Z","updated":"2018-08-29T09:57:02.419Z","comments":true,"path":"2017/03/09/java_class_init_/","link":"","permalink":"http://yoursite.com/2017/03/09/java_class_init_/","excerpt":"","text":"Java类从加载到卸载的生命周期 加载(Loading) | 1、获取对应类的二进制字节流 | 2、将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 ↓ 3、在堆中生成一个代表此类的java.lang.Class对象，作为方法区这些数据的访问入口。验证(Verification) | 1、文件格式验证(0xCAFEBABE，主、次版本号) | 2、元数据验证 | 3、字节码验证 ↓ 4、符号引用验证准备(Preparation) | 为类的静态变量分配内存并将其初始化为默认值(如static a=1,给a分配值0)，这些内存都将 | 在方法区中进行分配。 ↓解析(Resolution) | 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 ↓初始化(Initialization) | 执行类构造器()方法。()方法是由编译器自动收集类中的所有类变量的赋值 | 动作和静态语句块(static{}块)中的语句合并产生的。 ↓使用(Using) ↓卸载(Unloading) 几个例子来深入了解 被重新初始化的变量 1234567891011121314151617181920212223public class TestTest &#123; public static void main(String[] args) throws IOException &#123; StaticVariableInit singleTon = StaticVariableInit.getInstance(); System.out.println(\"count1=\" + singleTon.count1); System.out.println(\"count2=\" + singleTon.count2); &#125;&#125;class StaticVariableInit &#123; private static StaticVariableInit instance = new StaticVariableInit(); public static int count1; public static int count2 = 0; private StaticVariableInit() &#123; count1++; count2++; &#125; public static StaticVariableInit getInstance() &#123; return instance; &#125;&#125; 1、准备阶段，变量count1和count2都被赋值为0 2、初始化阶段开始，因为类构造器是按顺序执行赋值和静态语句块(static{})的，所以先执行new StaticVariableInit()，执行结束后count1和count2都为1 3、instance初始化完成后继续执行类构造器，count1没有赋值操作还是1，count2赋值为0 执行结果 12count1=1count2=0 子类构造函数调用时会先调用父类的构造函数 123456789101112131415161718192021222324252627282930313233343536373839class A &#123; public static int k = 0; static &#123; System.out.println(\"父类静态方法\"); &#125; &#123; System.out.println(\"父类非静态方法\"); &#125; public A() &#123; // 构造 System.out.println(\"父类构造\"); &#125; public A(String obj) &#123; System.out.println(\"父类构造 obj\"); &#125;&#125;class B extends A &#123; static &#123; System.out.println(\"子类静态方法\"); &#125; &#123; System.out.println(\"子类非静态方法\"); &#125; public B() &#123; // 构造 System.out.println(\"子类构造\"); &#125; public B(String obj) &#123; System.out.println(\"子类构造 obj\"); &#125;&#125;public class Demo &#123; public static void main(String args[]) &#123; B b = new B(new String()); &#125;&#125; 子类构造函数如果没有显示调用父类构造函数，那么会先调用父类的空构造。如果父类没有空构造那么必须显示指定要调用的父类构造函数，不然编译不会通过。 执行结果 123456父类静态方法子类静态方法父类非静态方法父类构造子类非静态方法子类构造 obj 123456789101112131415161718192021222324252627282930public class Text &#123; public static int k = 0; public static Text t1 = new Text(\"t1\"); public static Text t2 = new Text(\"t2\"); public static int i = print(\"i\"); public static int n = 99; public int j = print(\"j\"); &#123; print(\"构造块\"); &#125; static &#123; print(\"静态块\"); &#125; public Text(String str) &#123; System.out.println((++k) + \":\" + str + \" i=\" + i + \" n=\" + n); ++i; ++n; &#125; public static int print(String str) &#123; System.out.println((++k) + \":\" + str + \" i=\" + i + \" n=\" + n); ++n; return ++i; &#125; public static void main(String args[]) &#123; Text t = new Text(\"init\"); &#125;&#125; 12345678910111:j i=0 n=02:构造块 i=1 n=13:t1 i=2 n=24:j i=3 n=35:构造块 i=4 n=46:t2 i=5 n=57:i i=6 n=68:静态块 i=7 n=999:j i=8 n=10010:构造块 i=9 n=10111:init i=10 n=102","categories":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"JVM常用参数集合","slug":"jvm-option","date":"2017-03-08T13:20:30.000Z","updated":"2018-08-28T07:14:51.207Z","comments":true,"path":"2017/03/08/jvm-option/","link":"","permalink":"http://yoursite.com/2017/03/08/jvm-option/","excerpt":"","text":"实用型，会影响运行时环境 堆大小 -Xms 初始堆大小，默认内存的1/64(1GB) -Xmx 最大堆大小，默认物理内存的1/4 (&lt;1GB) -Xmn 年轻带大小 -XX:MinHeapFreeRatio=40 FullGC后如果老年代剩余容量小于40%则扩容,默认是40 -XX:MaxHeapFreeRatio=70 FullGC后如果老年代剩余容量大于70%则缩容,默认是70 -XX:NewSize=5m 年轻带大小，和-Xmn同时存在则以-Xmn为主(hotspot 25.101-b13) -XX:MetaspaceSize 1.8以后的永久带大小初始值 -XX:MaxMetaspaceSize 1.8以后的永久带最大值 -XX:Xss=512k 线程栈大小 配合GC -XX:+DisableEx 屏蔽System.gc() -XX:MaxTenuringThreshold={n} s区晋升最大次数 -XX:CMSInitiatingOccupancyFraction={n} CMS触发百分比 -XX:+UseCMSCompactAtFullCollection //CMS后进行碎片整理 -XX:CMSFullGCsBeforeCompaction={n} //CMS若干次后进行一次碎片 -XX:ParalelCMSThreads //CMS线程数量 -XX:ParalelGCThreads 指定GC线程数量 -XX:MaxGCPauseMills 最大GC停顿时间 -XX:GCTimeRatio 垃圾收集时间占总时间的比 大于3M的对象直接分配到old区,只能在ParNew和Serial使用,Parallel Scavenge不认识此参数 -XX:Pretenuresizethreshold=3145728 每次Minor GC执行完以后，虚拟机会检查之前晋升到老年代的平均大小是否大于老年代的剩余空间大小，如果大于，则发起一次Full/Major GC，如果小于，则查看HandlePromotionFailure值是否允许担保失败，如果允许，那只会进行一次Minor GC。如果不允许失败，那么也要改为进行一次Full/Major GC -XX:+HandlePromotionFailure 锁相关 -XX:+DoEscapeAnalysis 开启逃逸分析 -XX:+EliminateLocks 锁消除,基于逃逸分析 内存分配(参考) 在指针碰撞(Bump the Pointer)的内存分配方式中,为了防止每次给新对象分配内存都CAS申请内存,可以打开TLAB一次预先申请一小块内存给指定线程使用 另一种分配方式是空闲列表(Free List) ，空闲列表需要CAS吗？ -XX:+UseTLAB 打开本地线程分配缓冲区(Thread Local Allocation Buffer) 对象中的fields都是按照longs/doubles、ints、short/chars、bytes/booleans、opps(Ordianary Object Points)顺序分配的 -XX:+CompactFields 将一些短类型插入header和long/doubles之间 优化运行时环境 -Xverify:none 关闭字节码验证 关闭方法热度衰减。在指定时间内方法调用次数达不到即时编译器编译的要求，就会把方法调用次数减半 -XX:-UseCounterDecay -XX:CounterHalfLifeTime 通过此参数设置半衰期时间，单位秒 -XX:+PrintCompilation 打印被JIT编译的方法 System.gc()是否参与GC统计,默认为false.JVM会根据统计数据自适应调整GC参数 -XX:-UseAdaptiveSizePolicyWithSystemGC -agentlib:hprof=cpu=times,interval=10 采样统计各个方法占用cpu时长 -XX:-UseGCOverheadLimit 提前预测JVM是否OOM 辅助型，辅助排查 追踪初始化参数 -XX:+PrintCommandLineFlags 打印用户指定的或者JVM根据环境自适应的参数 -XX:+PrintFlagsFinal 初始化完成后打印参数 GC日志 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC 在GC前后打印出Heap信息 -Xloggc:f:\\gc.log 堆日志 -XX:+HeapDumpOnOutOfMemoryError OOM时导出堆到文件 -XX:+HeapDumpPath 堆导出的位置 -XX:+OnOutOfMemoryError OOM时执行一个脚本 verbose -verbose:class 打印出加载的class信息 -verbose:gc 打印出GC信息 -verbose:jni 打印出native方法调用的相关情况 命令查询jinfo -flag MaxTenuringThreshold {pid} 显示晋升阈值是多少，此命令可以查询当前JVM的某个参数 remarks:remark1 参考 remark2 著作权归作者所有。 商业转载请联系作者获得授权，非商业转载请注明出处。 作者：匿名用户 链接：http://www.zhihu.com/question/21367720/answer/19970887 来源：知乎 挖个坑，如果有人赞，我就把某大型网站的jvm启动参数贴上来。谢赞，填坑。 -server -Xmx2g -Xms2g -Xmn256m -XX:PermSize=128m -Xss256k -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -Xmn和-Xmx之比大概是1:9，新生代内存太大会导致young gc时间较长，一个好的Web系统应该是每次http请求申请内存都能在young gc回收掉，full gc永不发生。所以xmn的值应该是保证够用（够http并发请求之用）的前提下最小。 remark3 JDK1.7 update14的GC，有连线代表可以搭配使用","categories":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"Shell遍历和创建目录","slug":"shell_read_and_create_dir","date":"2017-02-18T10:30:30.000Z","updated":"2018-08-28T07:15:20.868Z","comments":true,"path":"2017/02/18/shell_read_and_create_dir/","link":"","permalink":"http://yoursite.com/2017/02/18/shell_read_and_create_dir/","excerpt":"","text":"需求：现在有一个文件处理脚本，可以将一个文件按一定规则处理并输出。接收两个参数：$1，文件输出路径$2，原文件路径现在需要写一个脚本，通过传递一个路径来把该路径下的所有文件都通过这个脚本处理并输出 my_bash.sh 是文件处理脚本名 12345678910111213141516171819202122232425262728293031323334353637383940#!bin/shfunction searchFile() &#123; # 参数是目录路径 out_root=$2 for file in $1 do # 是文件则开始压缩 echo $file if test -f $file then path=$&#123;file:$3&#125; # %/* 从右边开始取第一个/然后把他右边的字符都删掉，因为创建目录不能用文件名去创建 dir=$out_root$&#123;path%/*&#125; mkdir -p $dir my_bash.sh \"$2$path\" \"$file\" fi if test -d $file then # $file不带/，所以加上/ searchFile \"$file/*\" $2 $3 fi done&#125;input_dir=$1output_dir=$2#如果路径最后一个字符是/，删除之if [ $&#123;input_dir:0-1&#125; == '/' ]then input_dir=$&#123;input_dir%/*&#125;fiif [ $&#123;output_dir:0-1&#125; == '/' ]then output_dir=$&#123;output_dir%/*&#125;fi# 输入路径 输出路径 输入路径的长度searchFile $input_dir $output_dir $&#123;#input_dir&#125; 两个参数，\\$1 输入路径 \\$输出路口 主要遇到的问题： 用户输入的参数结尾有可能带/，也有可能不带/，所以在调用处理函数之前先统一格式 遍历文件夹，文件夹名后+*（如/data1/\\）表示该文件夹下所有子文件夹和文件组成的字符串 （空格隔开）*","categories":[{"name":"Shell","slug":"Shell","permalink":"http://yoursite.com/categories/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://yoursite.com/tags/Shell/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]}]}